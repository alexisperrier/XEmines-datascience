{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab SVM on Caravan\n",
    "\n",
    "Vous allez travailler sur le dataset Caravan\n",
    "\n",
    "[Caravan dataset on kaggle](https://www.kaggle.com/uciml/caravan-insurance-challenge)\n",
    "\n",
    "* 86 variables\n",
    "* Fortement déséquilibré\n",
    "    * No     5474\n",
    "    * Yes     348\n",
    "\n",
    "Le but est de prédire si une personne va acheter une poce d'assurance pour une caravane en fonction de son profil.\n",
    "\n",
    "Les 86 variables sont expliquées sur [cette page](https://www.kaggle.com/uciml/caravan-insurance-challenge/home).\n",
    "\n",
    "Nous n'allons pas rentrer dans le détail des variables.\n",
    "\n",
    "Le but de ce lab est d'appliquer les techniques de subsampling et oversampling pour améliorer le score. Nous comparerons aussi différentes métriques de scoring: AUC, F1-score et [Cohen's Kappa](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html)\n",
    "\n",
    "## 1) Data Processing\n",
    "\n",
    "* Chargez le dataset dans une dataframe pandas\n",
    "* Convertissez les variables categorielles en numerique avec LabelEncoder\n",
    "* Extraire les subset de train et test en veillant bien  a melanger (shuffle) le dataset et à stratifier les classes de façon a éviter que les train ou test subset ne contienne que peu ou pas assez de la classe minoritaire.\n",
    "\n",
    "## 2) Modelisation\n",
    "\n",
    "En considerant le dataset original déséquilibré, prendre le classifier support vector machine  [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html),\n",
    "\n",
    "Pour un SVC, calculer les scores (AUC, F1-score et Cohen's Kappa ) sur les training et testing subsets. Comparez differents kernel et differentes valeurs pour C et Gamma.\n",
    "\n",
    "Est-on en presence d'un bon classifier en terme de biais / underfitting et de variance / overfitting ?\n",
    "\n",
    "## 3) Grid search cross validation\n",
    "En utilisant [Grid Search CV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) et en définissant une série de parametres\n",
    "* C\n",
    "* gamma\n",
    "* kernel: linear, rbf, ...\n",
    "\n",
    "Trouvez le meilleur SVC.\n",
    "\n",
    "Observez vous une amélioration significative par rapport a vos modeles de l'etape 2) ?\n",
    "\n",
    "\n",
    "## 4) undersampling\n",
    "\n",
    "Nous allons essayer d'améliorer la performance du classifier en sous échantillonnant la classe majoritaire.\n",
    "\n",
    "Construisez X et y de facon a ce que \\\\(n_{Maj} \\simeq K n_{Min} \\\\) avec \\\\( K \\in [1,2] \\\\).\n",
    "\n",
    "Trouvez le meilleur classifier avec la methode Grid Search CV et calculer les scores AUC, F1 et Kappa.\n",
    "\n",
    "## 5) oversampling\n",
    "\n",
    "En utilisant la technique du bootstrap, sur échantilloner la class minoritaire.\n",
    "\n",
    "Construisez X et y de facon a ce que \\\\(n_{Min} \\simeq  \\frac{n_{Maj}}{ K} \\\\) avec \\\\( K \\in [1,3] \\\\).\n",
    "\n",
    "Trouvez le meilleur classifier avec la methode Grid Search CV et calculer les scores AUC, F1 et Kappa.\n",
    "\n",
    "Si on fait varier K, le rapport entre le nombre d'échantillons par classe, observe t on une valeur seuil de K pour laquelle les performances du classifier sont significativement meilleures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
