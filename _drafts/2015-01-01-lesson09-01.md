---
layout: slide
title: Lesson 09 - Classification 2 - Metrics and Logistic Regression
description: none
transition: slide
permalink: /09-classification-metrics-logistic-regression.html
theme: white
---
<section  data-background-color="#000">
    <h1 class = 'white' style ="border-top: thin solid #DDD;border-bottom: thin solid #DDD;">
        <img src="assets/ga_logo_black.png" style="float:left;top:0px;">
        General Assembly
    </h1>
    <p class = 'big_title'>9. Classification 2: Logistic Regression, Metrics, Transformations, </p>
</section>

<section data-markdown>
# Lesson 9
## LEARNING OBJECTIVES

* Why not use a simple linear regression to predict classification?
* Binomial Logistic Regression
* Transformations in Scikit
* Recap on encoding categorical values

</section>

<!-- Prework and review -->
<section  data-background-color="#DA0A13">
    <h1>Lesson #9</h1>
    <p class = 'big_title'>Review of Lesson 8</p>
</section>


<section data-markdown>
# Last Lesson Review

* Classification
* KNN
* Optimizing meta parameters with Grid search
* Visualization of higher dimensions
* Curse of dimensionality

</section>

<section data-markdown>
# Last session
### Any Questions?

* 3 types of classifications?
* What's KNN? What does the K stands for?
* How to visualize Higher Dimensions?
* The Curse of Dimensionality

Note:
Exit tickets
</section>

<!-- Today -->
<section  data-background-color="#22c8c6">
    <h1>Today</h1>
    <p class = 'big_title'>Logistic Regression</p>
</section>


<section data-markdown>
# More on Classification vs Regression

Why not use linear regression to predict some medical condition such as

* 0: Stroke,
* 1: Epileptic seizure
* 2: Overdose

</section>

<section data-markdown>
# More on Classification vs Regression

Why not use linear regression to predict some medical condition such as

* 0: Stroke,
* 1: Epileptic seizure
* 2: Overdose

Encoding it like that and using Linear Regression implies:

* order of the encoding
* equal distance between codes
</section>

<section data-markdown>

# In the binary case:

* 0: Stroke,
* 1: Epileptic seizure


Possible to use linear regression as a proxy for a probability

* May end up with results outside the [0,1] range

So classification specific models better!

</section>

<section data-markdown>
# The Default dataset

Predict whether a person will default on his/her credit card payment

The data:

* Annual Income
* Monthly credit card balance
* is the person a student?

[Notebook](http://localhost:8888/edit/gads/09_logistic_regression/py/L9-logistic-regression.py)

* Load the dataset
    df = pd.read_csv('../data/Default.csv')
* Describe it
* boxplot balance and income vs default

</section>


<section data-markdown>
# Logistic regression
Types of Logistic Regression:

* Binary Logistic Regression: The target variable has only two possible outcomes such as Spam or Not Spam, Cancer or No Cancer.
* Multinomial Logistic Regression: The target variable has three or more nominal categories such as predicting the type of Wine.
* Ordinal Logistic Regression: the target variable has three or more ordinal categories such as restaurant or product rating from 1 to 5.
</section>


<section data-markdown>
# Logistic regression

Instead of predicting the class, we predict the probability that the outcome belongs to a class i.e.

$$ P(Y = 1/ X) $$

which we note \\( p(X) \\)

and similarly to Linear Regression we want a simple linear model for that probability

$$ P(Y=1 / X) =  p(X) = \beta_0 + \beta_1 X $$

but that still does not give us values between [0, 1]

</section>

<section data-markdown>
# Logistic regression

So instead we feed the linear model to the sigmoid function

$$ f(z) = \frac{e^{z} }{1 + e^{z}} =  \frac{1 }{1 + e^{-z}} $$


We feed \\( z = \beta\_0 + \beta\_1 X \\) to the sigmoid function

$$ p(X) = \frac{e^{\beta\_0 + \beta\_1 X} }{1 + e^{\beta\_0 + \beta\_1 X}}  $$

because this function shrinks \\( \mathbb{R} \\)  to \\( [0,1] \\)
</section>

<section data-markdown>
# Sigmoid function

![sigmoid function](assets/09/sigmoid.svg)
</section>

<section data-markdown>
# Odds ratio

$$ p(X) = \frac{e^{\beta\_0 + \beta\_1 X} }{1 + e^{\beta\_0 + \beta\_1 X}}  $$

This is called the **odds ratio**: ratio of the probability the event happens over the probability it does not happen
$$
\frac{p(X)}{ 1 -p(X)} = e^{\beta\_0 + \beta\_1*X}
$$

* Odds ratio  \\( \in [0, +\infty] \\)
* Odds close to 0: low probability of the event happening
* Odds close to \\( +\infty \\) : low probability of the event happening

</section>

<section data-markdown>
# Log-Odds ratio
This is called the **log-odds ratio**: the log of the odds ratio

$$
log(\frac{p(X)}{ 1 -p(X)}) = \beta\_0 + \beta\_1 X
$$

Increase in \\( \beta\_1 \\) => results in increase in \\( p(X)\\).

Not as direct and linear as in the case of linear regression.

</section>

<section data-markdown>
# Odds Ration interpretation

Exemple in the default dataset

\\( p(X) = 0.2 \iff  \frac{0.2}{1 -0.2} = 0.25 \\)

* 1/5 people with ods 1/4 will default

\\( p(X) = 0.9 \iff  \frac{0.9}{1 -0.9} = 9 \\)

* 9 out of 10 people (90%)  with ods 9 will default

</section>

<section data-markdown>
# Estimation of LR coeffs

[Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)

</section>

<section data-markdown>
# Lab on Default Dataset

Using:

        import statsmodels.api as sm
        # Add the constant term to X  [[1,x_1], [1,x_2], ..., [1,x_n], ] expected by statsmodel (not by scikit learn)
        X_sm = sm.add_constant(df.balance)
        clf = sm.Logit(df.default_fact, X_sm).fit()
        print(clf.summary().tables[1])


1. default vs balance
2. default vs balance, income and student

* Calculate the probability of default for
    * a student with a credit card balance of \\$1500 and income of \\$40k
    * a non-student, same balance and income

Why is the coefficient for student positive when student is the only factor and negative in the case of multilinomial logistic regression?

</section>

<section data-markdown>
# Lab on Default Dataset

- Z test: the regression coefficient divided by its standard error.
    The larger the better
- P values: % of the null hypothesis that the coefficient is pure random

</section>

<!-- part 2 metrics -->

<section data-markdown>
# Metrics
So far we've only looked at accuracy: Number of correctly identified classes

Correctly identified:

* TP = True Positive
* TN = True Negatives

Incorrectly identified:

* FP = False Positive
* FN = False Negatives
</section>

<section data-markdown>
# Metrics

![FP and FN](assets/09/pregnant.jpg)
</section>


<section data-markdown>
# Accuracy

* TP = True Positive
* TN = True Negatives
* FP = False Positive
* FN = False Negatives

How to you define accuracy?
</section>

<section data-markdown>
# Accuracy

* TP = True Positive
* TN = True Negatives
* FP = False Positive
* FN = False Negatives

\\( Accuracy = \frac{ TP + TN  }{TP + FP + TN + FN}   \\)

</section>

<section data-markdown>
# Confusion matrix


![confusion matrix](assets/09/confusion_matrix.png)

* TP, TN?
* FN, FP?
* Accuracy?



</section>

<section data-markdown>
# Confusion matrix
In scikit:

        from sklearn.metrics import confusion_matrix
        y_true = [0,0,0,0,0,1,1,1,1,1]
        y_pred = [0,0,0,1,1,0,1,1,1,1]
        confusion_matrix(y_true, y_pred)

</section>

<section data-markdown>
# Notebook

Split Default into train and test (80/20)

* On training dataset: 5 fold CV with Logistic Regression on all regressors
* Use GridSearchCV with
        parameters = {'solver': ['newton-cg','lbfgs','liblinear','sag']}
* What's the best model? Accuracy? best parameter?
* Print the confusion matrix for the best model on the test set

* Compare with best model with KNN 5 fold CV and K = [2,5,10, 20]

Same results?

</section>
<section data-markdown>
# What's the right threshold?

* for your best LR model, print the results of predict() and predict_proba()
* predict() returns a class for all new samples
* predict_proba() returns a probability

What's the threshold?

Use predict_proba and a different threshold => you should find a different confusion matrix

So what's the best one?

</section>

<section data-markdown>
# AUX and ROC Curve

* TPR = \\( \frac{  TP }{ P}  = \frac{  TP }{ TP + FN} \\) aka **Sensitivity** or **Recall**
* FPR = \\( \frac{  FP }{ N}  = \frac{  FP }{ FP + TN} \\)  aka **Fall-out**

</section>


<section data-markdown>
# AUX and ROC Curve

### Receiver operating characteristic

ROC = TPR vs FPR for different Thresholds

sklearn.metrics.roc_curve returns TPR, FPR

plot to get the ROC Curve

notice that KN  also has a predict_proba

on the same plot: ROC curve for KNN

</section>
<section data-markdown>
# AUX and ROC Curve
The AUX is Area under the Curve

sklearn.metrics.roc_auc_score

</section>
<section data-markdown>
# AUX and ROC Curve

So what's your best model KNN / LR according to AUC?

</section>


<section data-markdown>
# Pre processing the data with scikit

[preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html)

* scaling
* normalizing
* remove linear correlation with PCA
* binarization
* encoding categorical features

with

* fit
* transform

</section>
<section data-markdown>
# Encode categorical value
One Hot encoding, DictVectorizer or get_dummies
Label encoder
Factorize on pandas

http://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor
and
http://fastml.com/converting-categorical-data-into-numbers-with-pandas-and-scikit-learn/
</section>


<section data-markdown>
# Scaling and centering

Let's scale and normalize the income and balance and see if that helps

        load default dataset
        train, test split

train 3 models over df[balance, income]

        linear regression
        Knn K = 2,
        SVC

Compare accuracy before and after scaling

</section>

<section data-markdown>
# PCA to decorrelate

Use 3 regressor

then PCA to 2

and diff?

http://scikit-learn.org/stable/auto_examples/plot_digits_pipe.html#example-plot-digits-pipe-py

</section>


<section data-markdown>
# Make classification

[make_classification](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification)

n_features = n_informative + n_redundant + n_repeated + noisy feature

* what's the influence of n_redundant
* what's the influence of noisy features,
* does repeating features help? why?
* what's the catch?

</section>

<section data-markdown>
# Project 3

</section>
<section data-markdown>
# Links
* http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/
* https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms

* [Understanding Logistic Regression in Python
](https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python) on datacamp
</section>
