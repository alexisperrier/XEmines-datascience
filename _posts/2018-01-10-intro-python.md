---
layout: slide
title: 1) Intro et Python
description: none
transition: slide
permalink: /1-intro-python
theme: white
---

<section data-markdown>
<div class=centerbox>
<p class=top> Data science</p>
<p style ='font-size:28px;'>Analyse prédictive et machine learning <br /><br /><br /></p>
<p style ='font-size:28px;'>&nbsp;</p>
<p style ='font-size:28px;'>&nbsp;</p>
</div>
</section>


<section>
<div style='float:center;'>

    <div data-markdown>
    <img src=/assets/01/presentation_alexis_perrier.png>
    </div>
</div>
</section>

<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>

* Concepts et Methodes
    * biais, variance et overfitting
    * transformations des données
    * feature engineering et feature selection
    * métriques et techniques de scoring

* datasets
    * iris, titanic, housing
    * caravan, arbres, ...

* Python
    * notebook jupyter, anaconda
    * pandas, numpy
    * statsmodel et surtout scikit-learn
    </div>
</div>


<hr class='vline' />

<div style='float:left; width:45%;  '>
<div data-markdown>
# Programme

* Machine learning avec scikit-learn
    * analyse prédictive
    * classification et régression

* Approches statistiques classiques:

    * régression linéaire,
    * régression logistique

* Modélisation machine learning
    * Random Forests, XGBoost
    * Support vector machines
    * Gradient stochastique
    * Adaboost, perceptron
    * Naive Bayes

</div>
</div>

</section>
<section data-markdown>
# Déroulement

* Matin: théories, méthodes et démos

* Après-midi: Lab, workshop => notebooks jupyter

* Quizzes

* Projet final: Kaggle

    * https://www.kaggle.com/c/house-prices-advanced-regression-techniques/

</section>


<section data-markdown>
<div class=centerbox>
<p class=top>data science - machine learning - predictive analytics - intelligence artificielle - deep learning</p>
</div>
</section>

<section >
<div data-markdown>
<img src=/assets/01/tweet_when_youre_fundraising.png width = 800>
</div>
</section>

<section data-markdown>
![data science sexiest job](/assets/01/data_science_sexiest_job.jpeg)
![demand](/assets/01/data-scientist-demand.jpg)
</section>


<section data-markdown>
# data science - machine learning - predictive analytics - intelligence artificielle - deep learning

* **Data Analysis, Data Mining** : Exploration, trouver les tendances, les evolutions, les anomalies, etudier les corrélations.

* **Statistiques** : Trouver le modèle qui explique au mieux les données

* **Machine learning** : Le modèle apprend automatiquement à partir des données. Dimension importante d'apprentissage, de training

* **Analyse prédictive**: Construire ou entrainer des modèles qui peuvent *"prédire"* à partir de données passées.
* **Deep Learning** : Analyse prédictive supervisée avec des réseaux de neurones


[What is the difference between Data Analytics, Data Analysis, Data Mining, Data Science, Machine Learning, and Big Data?](https://www.quora.com/What-is-the-difference-between-Data-Analytics-Data-Analysis-Data-Mining-Data-Science-Machine-Learning-and-Big-Data-1)

</section>

<section data-markdown>
# Stats vs machine learning

# A tiny drop of History

Great article [Forbes: A Very Short History Of Data Science](http://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/#bbea13569fd2)

2001 Leo Breiman, Berkeley, publishes “[Statistical Modeling: The Two Cultures](https://projecteuclid.org/euclid.ss/1009213726)”:

“*There are two cultures in the use of statistical modeling to reach conclusions from data.*

**One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown.**

*The statistical community has been committed to the almost exclusive use of data models.*

*This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.*”


</section>



<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
<img src=/assets/01/ds_meme.jpg>
    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Data Science: skills
<img src=/assets/01/ven_diagrams.png>
    </div>
</div>
</section>



<section data-markdown>
<img src=/assets/01/data_science_close_up.png width = 650>
</section>

<section data-markdown>
# Champs d'applications

* **Predictions**: market, demand, supply prices, population, weather, earthquakes, ...

* **Patterns**: customer behavior patterns

* **Detection**: Spam, Fraud, Failures, Cyber attacks

* **Extracting meaning** from large sets of data: handwritten health records, exoplanets

* **NLP**: translation, speech to text, speech recognition, sentiment analysis, topic modeling, spell checking

* **Recommender systems**: Netflix, Spotify, Amazon

* **Ranking systems**: search results

* **Autonomous systems** (reinforcement learning / AI): playing games, self driving cars, drones

* **Time series**: algorithmic trading, signal processing, IoT
* **Image / Video**: automatic captionning, face and object recognition, ...

</section>

<section data-markdown>
<div class=centerbox>
<p class=top> Data science workflow</p>
</div>
</section>


<section data-markdown>

![](/assets/01/predicsis_data_science_workflow.png)

</section>

<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
## A) Les données

1.  Définir le problème
    * De quelles données disposent-on ?
    * Sont-elles accessibles ?
    * Que veut-on améliorer ?
    * Comment mesurer l'efficacité de la solution, du modèle ?
    * Choix des métriques

2. ETL: Extraction Transform Load

    * Constituer le dataset
    * Explorer et comprendre

## là commence le travail de modélisation

3. Travailler sur les variables
    * Nettoyer et transformer : outliers, missing values, distributions, correlations, ...
    * feature engineering
    * feature selection
    </div>
</div>
</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
<img src=/assets/01/aws_ml.png width=200>
<img src=/assets/01/gcloud_ml.png width=200>
    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
## B) Machine Learning

4) Outils et plateforme
* Cloud (AWS, Google Cloud, Azure) ou local
* python (scikit-learn) ou R ou ...
* Modèles classiques
* Deep learning (TF, Keras, pytorch, ...)

    </div>
</div>
</section>
<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
<img src=/assets/01/ml_map.png>
    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
## B) Machine Learning

5) Modélisation

* Choisir la bonne approche, le bon type de modèle
* *Train* le modèle
* Evaluer le modèle, scoring, ....
* Sélectionner les meilleurs parametres du modèle

6) Appliquer sur de nouvelles données

* on quitte un environnement controlé (laptop / labo) pour le monde réel

* le modèle generalise t il bien ?
* les données ont-elles changées ?


    </div>
</div>
</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>



## D) Mise en production

* ingénierie logicielle
* API
* streaming

    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>

## C) Nouvelle itération

7) Présentation des résultats

* cycle itératif court
* communication
* data visualization

8) reprendre le problème au niveau des données
* il en faut plus
* il faut de nouvelles variables
* ....

ou au niveau de la définition du problème

* qu'est ce qu'on veut optimiser
* comment le mesurer
* accessibilité des données
    </div>
</div>
</section>
<!-- ======================================================== -->

<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
<img src=/assets/01/predicsis_data_science_workflow.png>
    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
## A) Les données

* 1)  Définir le problème

* 2) ETL: Extraction Transform Load

* 3) Travailler sur les variables

## B) Machine Learning

* 4) Outils et plateforme
* 5) Modélisation
* 6) Le test des nouvelles données

## C) Nouvelle itération

* 7) Présentation des résultats
* 8) reprendre le problème


## D) Mise en production

    </div>
</div>
</section>




<section data-markdown>
# Data science - machine learning - predictive analytics

[Can I learn Machine Learning completely with Kaggle?](https://www.quora.com/Can-I-learn-Machine-Learning-completely-with-Kaggle)

*While modeling is the sexy part of any machine learning project, it is also one of the parts that you will actually spend the least amount of time on.*

*In a business environment 80–90% of the time will be spent on defining problems worthwhile solving, defining **evaluation metrics**, procuring access to the **raw data**, **understanding** the data, generating **features**, presenting findings, and working with engineers to deploy the model to production via API or other automated approaches.*

</section>


<section data-markdown>
<img src=/assets/01/your_plan_vs_reality.jpeg height=500>

</section>


<section data-markdown>
# Analyse prédictive

![](/assets/01/predictive_analytics.png)

[Predictive analytics](https://en.wikipedia.org/wiki/Predictive_analytics) : analyze current and historical facts to make predictions about **future or otherwise unknown events**. Predictive analytics provides a predictive score (probability).

</section>

<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
# Non Supervisée

Le dataset d'apprentissage n'inclut pas de variable cible. Il n'y a pas de **ground truth**

* logique de clustering, de classification automatique des échantillons  sans connaitre a priori le nombre de classes
* notion de similarité et de distance entre les échantillons
* K-means, K-NN, ...


<img src=/assets/01/ch1_unsupervised_learning.png>

    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Supervisée

Le dataset d'apprentissage inclut la variable  à prédire  [cible]. On a un certain nombres d'exemples sur lesquels on peut entrainer un modèsle

* logique de scoring, de classification et de prediction
* Random forest, Regression lineaire ou logistique, SVM, ...
* Classification: On connait le nombre de classes

<img src=/assets/01/ch1_supervised_learning.png>
    </div>
</div>
</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
# Classification

La variable cible est discrete, une catégorie, une classe

### Cas binaire
* Achat, resiliation, click
* Survie, maladie, succes examen, admission,
* Positif ou negatif
* Spam, fraude

### Multi class - multinomiale
* Catégories, types (A,B,C),
* Positif, neutre ou negatif
* Espèces de plantes d'animaux, ...
* Pays, planetes

### Ordinale

* Notes, satisfaction, ranking


    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Regression

La variable cible est continue

* Age, taille, poids,

* nombre d'appels, de clicks, volume de vente, consommation

* Température, Salaire, ...

* Probabilité d'une action

* Temps, délai, retard

    </div>
</div>
</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
# Classification à regression

* Prédire une probabilité au lieu d'une classe

$$
0 < P( x \in A) < 1
$$


    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Regression à classification

* discrétiser la variable

Age =>

* 0 - 12
* 12 - 24
* 25 - 49
* 50 - 65
* plus de 65



    </div>
</div>
</section>


<section data-markdown>
<div class=centerbox>
<p class=top>Environnement</p>
<p style ='font-size:28px;'>Python, anaconda et jupyter </p>
</div>
</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
<img src=/assets/01/Python-Logo-PNG-Image.png width=400>
<img src=/assets/01/guidovanrossum.jpg width=400>


    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Python

* Beaucoup d’applications: web, data science, scientific, …

* Créé en 1991 par Guido von Rossum! 30 ans déjà!

* 130.000 packages et librairies

* Duck typing, pas de compilation, pas de ; ou de {}

* Indentation => le code est lisible

* Performances

* Mais il y a des surprises, des incoherences, des idioms, …

* Python 2.7 ou python 3.6


    </div>
</div>
</section>


<section data-markdown>
<img src=/assets/01/python_projections_on_stackoverflow.png height=650>
</section>

<section >

<div data-markdown>
# Python

* list comprehension

```liste_a = [n for n in range(100) if n % 2 ==0 ]```


* pandas dataframe

``` df = pd.read_csv(filename) ```

```df = df.groupby(by = 'age' ).reset_index(inplace = True)```

```df = df.age.apply(lambda a : une_fonction(a) )
```

* notebook jupyter


    > jupyter notebook


* exemple

[Python_Pandas_Demo.ipynb](Python_Pandas_Demo.ipynb)

</div>

</section>


<section data-markdown>
# Quel Python avez-vous?

Dans un terminal

```> python --version
```

![](/assets/01/python_version.png)

</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
<img src=/assets/01/anaconda_logo.png>

[https://www.anaconda.com/](https://www.anaconda.com/)


    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Anaconda

* Distribution Anaconda et package manager conda

```conda install package_name
```

* Data science en python:

    * Dataframe: pandas, dask

    * Math, science: numpy, scipy, statsmodel,

    * Dataviz: matplotlib, plot.ly, bokeh

    * Deep learning: Tensorflow, Keras, Mxnet, …

    * Text: Gensim, NLTK, Spacy.io

    * scikit-learn: http://scikit-learn.org/

    </div>
</div>
</section>


<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
# [http://jupyter.org/](http://jupyter.org/)
<img src=/assets/01/jupyter_logo_ecosystem.png>
<img src=/assets/01/jupyter_architecture.png>


    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Jupyter notebook

* Executer du code dans le navigateur
* Partage et reproductabilité
* Calcul et visualisation

* Multilingue: R, python, ...
* Local ou cloud
    * $ Jupyter notebook
    * AWS Sagemaker, Google datalab, Kaggle kernels
* A base de cellules
    * Documentation: markdown et latex
    * Kernels: Python, R, Julia, Scala, …
    * Shell terminal

* Alt: Beaker, Apache zeppelin

* Mais: Le code est séquentiel + State problems

    </div>
</div>
</section>



<section data-markdown>
# Editeurs de texte

<img src=/assets/01/atom_io-card.png height=150px>

<img src=/assets/01/sublime_text_logo.png height=150px>

<img src=/assets/01/spyder_readme_banner.png height=150px>

</section>



<section data-markdown>
<div class=centerbox>
<p class=top>Récapitulatif</p>
<p class=top></p>
</div>
</section>


<section data-markdown>

# Récapitulatif

* Programme des 2 semaines
* Révisions de python
* Différence entre Data Science, Machine Learning et analyse prédictive
* Approche statistique vs approche machine learning
* Déroulement d'un projet de Data science
* Supervisée vs non-supervisée
* Regression vs Classification
* Anaconda, Python et Jupyter

</section>

<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
# Notebook d'exploration et Pandas

* load dataset dans une dataframe pandas
* visualisation des variables
* statistiques des variables numériques et occurences des catégories
* trouver les outliers et les enlever

Arrondissements:

* quels arrondissements ont
    * le plus d'arbres
    * le plus de variétés d'arbres
    * les arbres les plus hauts, les plus larges
* hauteur et circonférence en fonctions des espèces d'arbres
* Comment sont définis les arbres dit remarquables?
    * comment traiter les valeurs manquantes de cette colonne

Domanialité
    * memes questions que pour les arrondissements: variétés, hauteur, ...

En joignant le dataset arrondissement qui donne la superficie des arrondissements

Creer une variable code_postale dans le dataset arbres, qui permette de joindre les 2 fichiers: PARIS 2E ARRDT => 75102

Joindre les 2 fichiers

Calculer le nombre d'arbres par arrondissement en utilisant groupby et count()
enlever les arrondissement qui ne sont pas dans Paris



    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>
# Lab

2 datasets

* 200.000 arbres de Paris
    * Espèces, genres, famille
    * Adresse, geolocalisation
    * Environnement: rue, jardin, ..
    * hauteur et circonférence

* Arrondissement de Paris
    * Superficie

    </div>
</div>
</section>



<section>
<div style='float:right; width:45%;  '>
    <div data-markdown>
    </div>
</div>
<hr class='vline' />
<div style='float:left; width:45%;  '>
    <div data-markdown>

    </div>
</div>
</section>
